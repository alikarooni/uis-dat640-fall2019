{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from text using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our toy document collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"This is the first document\",\n",
    "    \"This is the second second document\",\n",
    "    \"Document three is short\",\n",
    "    \"Document four is boring\",\n",
    "    \"Document five five five five five is where we stop\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using raw term counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "counts = count_vect.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary (may also be viewed as a list of features using `count_vect.get_feature_names()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boring': 0,\n",
       " 'document': 1,\n",
       " 'first': 2,\n",
       " 'five': 3,\n",
       " 'four': 4,\n",
       " 'is': 5,\n",
       " 'second': 6,\n",
       " 'short': 7,\n",
       " 'stop': 8,\n",
       " 'the': 9,\n",
       " 'this': 10,\n",
       " 'three': 11,\n",
       " 'we': 12,\n",
       " 'where': 13}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 0 0 0 1 1 0 0 0]\n",
      " [0 1 0 0 0 1 2 0 0 1 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 1 0 0 0 1 0 0]\n",
      " [1 1 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 5 0 1 0 0 1 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(counts.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use l1 normalization, i.e., the sum of vector elements is 1. The default would be l2 normalization, i.e., the sum of squares of vector elements is 1. See the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(norm='l1', use_idf=False)\n",
    "counts_tf = tf_transformer.fit_transform(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.2         0.2         0.          0.          0.2         0.\n",
      "   0.          0.          0.2         0.2         0.          0.          0.        ]\n",
      " [ 0.          0.16666667  0.          0.          0.          0.16666667\n",
      "   0.33333333  0.          0.          0.16666667  0.16666667  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.25        0.          0.          0.          0.25        0.\n",
      "   0.25        0.          0.          0.          0.25        0.          0.        ]\n",
      " [ 0.25        0.25        0.          0.          0.25        0.25        0.\n",
      "   0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.1         0.          0.5         0.          0.1         0.\n",
      "   0.          0.1         0.          0.          0.          0.1         0.1       ]]\n"
     ]
    }
   ],
   "source": [
    "print(counts_tf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF-IDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer(norm='l1', use_idf=True)\n",
    "counts_tfidf = tfidf_transformer.fit_transform(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.09861229  1.          2.09861229  2.09861229  2.09861229  1.\n",
      "  2.09861229  2.09861229  2.09861229  1.69314718  1.69314718  2.09861229\n",
      "  2.09861229  2.09861229]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.1336022   0.28037922  0.          0.          0.1336022\n",
      "   0.          0.          0.          0.22620819  0.22620819  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.10434581  0.          0.          0.          0.10434581\n",
      "   0.43796278  0.          0.          0.17667281  0.17667281  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.16136256  0.          0.          0.          0.16136256\n",
      "   0.          0.33863744  0.          0.          0.          0.33863744\n",
      "   0.          0.        ]\n",
      " [ 0.33863744  0.16136256  0.          0.          0.33863744  0.16136256\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.05322292  0.          0.55847135  0.          0.05322292\n",
      "   0.          0.          0.11169427  0.          0.          0.\n",
      "   0.11169427  0.11169427]]\n"
     ]
    }
   ],
   "source": [
    "print(counts_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** To be able reuse the vocabulary later, e.g., when applying the learned model on the text set, the vocabulary needs to be saved (i.e., dumped to a file). In case of TF-IDF weighting, the IDF values also need to be saved. While saving IDF values is possible, there is currently no support for loading these back from file. Therefore, the workaround is to dump the entire `TfidfTransformer` model to file.\n",
    "\n",
    "Create a `data` folder before running the code below. We use `joblib` (scikit learn's replacement of `pickle`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/vocabulary.pkl']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(count_vect.vocabulary_, \"data/vocabulary.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping `TfidfTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/tfidf_transformer.pkl']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf_transformer, \"data/tfidf_transformer.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing new document by loading the saved vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_docs = [\"document second five the unseen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = joblib.load(\"data/vocabulary.pkl\")\n",
    "count_vect2 = CountVectorizer(vocabulary=vocab)\n",
    "counts2 = count_vect2.fit_transform(new_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that \"ten\" is not in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boring', 'document', 'first', 'five', 'four', 'is', 'second', 'short', 'stop', 'the', 'this', 'three', 'we', 'where']\n",
      "[[0 1 0 1 0 0 1 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(count_vect2.get_feature_names())\n",
    "print(counts2.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to get TFIDF weights; this is not possible by simply loading the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_transformer2 = TfidfTransformer(norm='l1', use_idf=True)\n",
    "counts_tfidf2 = tfidf_transformer2.fit_transform(counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.25  0.    0.25  0.    0.    0.25  0.    0.    0.25  0.    0.    0.\n",
      "   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(counts_tfidf2.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try with the saved `TfidfTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_transformer3 = joblib.load(\"data/tfidf_transformer.pkl\")\n",
    "counts_tfidf3 = tfidf_transformer3.transform(counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.14513005  0.          0.30457171  0.          0.\n",
      "   0.30457171  0.          0.          0.24572654  0.          0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(counts_tfidf3.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
