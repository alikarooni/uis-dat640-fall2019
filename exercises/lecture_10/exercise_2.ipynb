{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #2: Document-at-a-time scoring\n",
    "\n",
    "Implement term-at-a-time scoring using vector space retrieval with TFIDF term weighting and dot product similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td_matrix = {\n",
    "    \"beijing\": [0, 1, 0, 0, 1],\n",
    "    \"dish\": [0, 1, 0, 0, 1],\n",
    "    \"duck\": [3, 2, 2, 0, 1],\n",
    "    \"rabbit\": [0, 0, 1, 1, 0],\n",
    "    \"recipe\": [0, 0, 1, 1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of documents is set manually for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DOCS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the corresponding inverted index\n",
    "\n",
    "The postings hold (docID, freq) pairs. docID indices start from 0\n",
    "\n",
    "`doclen` stores the document length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beijing': [(1, 1), (4, 1)],\n",
      " 'dish': [(1, 1), (4, 1)],\n",
      " 'duck': [(0, 3), (1, 2), (2, 2), (4, 1)],\n",
      " 'rabbit': [(2, 1), (3, 1)],\n",
      " 'recipe': [(2, 1), (3, 1), (4, 1)]}\n"
     ]
    }
   ],
   "source": [
    "inv_idx = {}\n",
    "doclen = {}\n",
    "for term, vec in td_matrix.items():\n",
    "    inv_idx[term] = []\n",
    "    for doc_id, freq in enumerate(vec):\n",
    "        if freq > 0:\n",
    "            inv_idx[term].append((doc_id, freq))\n",
    "            doclen[doc_id] = doclen.get(doc_id, 0) + freq\n",
    "\n",
    "pprint(inv_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This class provides access to the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InvIndex(object):\n",
    "    def __init__(self, idx_contents):\n",
    "        self.idx = idx_contents\n",
    "    \n",
    "    def postings(self, term):\n",
    "        return self.idx.get(term, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the InvIndex class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = InvIndex(inv_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDF calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(term):\n",
    "    return math.log(NUM_DOCS / len(idx.postings(term))) if len(idx.postings(term)) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-at-a-time scoring\n",
    "\n",
    "We utilize the fact that the posting lists are ordered by document ID. \n",
    "The posting lists of the query terms are iterated parallel to each other.\n",
    "Each document is scored according to\n",
    "\n",
    "$score(q,d) = \\sum_{t \\in q} w_{t,d} \\times w_{t,q}$\n",
    "\n",
    "where $w_{t,d}=tf_{t,d}\\times idf_t$ and $w_{t,q}=tf_{t,q}$\n",
    "\n",
    "  - Use normalized frequencies for TF weight, i.e., $tf_{t,d}=\\frac{f_{t,d}}{|d|}$, where $f_{t,d}$ is the number of occurrences of term $t$ in document $d$ and $|d|$ is the document length (=total number of terms). (It goes analogously for the query.)\n",
    "  - Compute IDF values using the following formula: $idf_{t}=\\log \\frac{N}{n_t}$, where $N$ is the total number of document and $n_t$ is the number of documents that contain term $t$. \n",
    "\n",
    "(I.e., the same as in Exercise #1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_dt(query, index):\n",
    "    # Change the sequence of query terms into a \"term: freq\" dictionary\n",
    "    qry = dict(Counter(query))\n",
    "\n",
    "    scores = {}  # holds the final document scores (this should be a priority list, but for simplicity we use a dictionary here)\n",
    "    \n",
    "    # Iterate through each document\n",
    "    for doc_id in range(NUM_DOCS):            \n",
    "        # First, we collect the document term frequencies from the index\n",
    "        # (Essentially, we just \"recover\" the document's contents from the index.)\n",
    "        f_td = {}  # holds the term frequencies in the document\n",
    "        for term in qry.keys(): \n",
    "            # TODO: get the frequency of query term i from the posting list\n",
    "            # Utilize the fact that the posting lists are ordered by document ID!\n",
    "            f_td[term] = 0\n",
    "                    \n",
    "        # Then, we score the document\n",
    "        score = 0  # Holds the document's retrieval score\n",
    "        for term, f_tq in qry.items():\n",
    "            # Incement the document's score according to the given query term\n",
    "            tfidf_td = 0  # TODO: compute the term's TFIDF score in the document\n",
    "            tf_tq = f_tq / len(query)\n",
    "            score += tfidf_td * tf_tq\n",
    "        # Final document score\n",
    "        scores[doc_id] = score\n",
    "    return scores\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = [\"beijing\", \"duck\", \"recipe\"]\n",
    "scores = score_dt(query, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1: 0.0\n",
      "D2: 0.0\n",
      "D3: 0.0\n",
      "D4: 0.0\n",
      "D5: 0.0\n"
     ]
    }
   ],
   "source": [
    "for doc_id, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(\"D\" + str(doc_id + 1) + \":\", round(score, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
