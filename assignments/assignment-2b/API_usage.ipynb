{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search API usage example\n",
    "\n",
    "This notebook shows how to use the Search API.\n",
    "\n",
    "This API (see the [source code here](api.py)) acts as a broker between users and the Elasticsearch service, hosted on a cloud.  It basically recives requests, passes them onto Elastissearch (via the [Python client](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html)), and returns the results as JSON.  It mirrors the parameterization of the respective Elasticsearch API methods.\n",
    "\n",
    "Note that you don't need to run anything locally, the source code is merely provided for transparency.\n",
    "\n",
    "![Search API](search_api.png)\n",
    "\n",
    "You talk to the Search API using HTTP requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "API = \"http://gustav1.ux.uis.no:5002\"\n",
    "\n",
    "MAIN_INDEX = \"clueweb12b\"\n",
    "ANCHORS_INDEX = \"clueweb12b_anchors\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "Executing a search query using [es.search()](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.Elasticsearch.search) and returns the search hits\n",
    "\n",
    "Parameters:\n",
    "  - `q` (mandatory): query\n",
    "  - `df` (mandatory): field to search in\n",
    "  - `size` (optional): number of hits to return (default: 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(indexname, query, field, size=10):\n",
    "    url = \"/\".join([API, indexname, \"_search\"]) + \"?\" \\\n",
    "          + urllib.parse.urlencode({\"q\": query, \"df\": field, \"size\": size})\n",
    "    response = requests.get(url).text\n",
    "    return json.loads(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating rankings for a set of queries\n",
    "\n",
    "The code below is used for generating the first-pass (BM25) ranking (top-100 documents based on the content field).\n",
    "\n",
    "(For your actual submissions, make sure you use the file that is provided in your private repository. You may use the code below to generate a temporary file that can be used during development.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERIES_FILE = \"data/queries.txt\"\n",
    "OUTPUT_FILE = \"data/ranking_bm25_temp.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_queries(query_file):\n",
    "    queries = {}\n",
    "    with open(query_file, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            qid, query = line.strip().split(\" \", 1)\n",
    "            queries[qid] = query\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking documents for [201] 'raspberry pi'\n",
      "Ranking documents for [202] 'uss carl vinson'\n",
      "Ranking documents for [203] 'reviews of les miserables'\n",
      "Ranking documents for [204] 'rules of golf'\n",
      "Ranking documents for [205] 'average charitable donation'\n",
      "Ranking documents for [206] 'wind power'\n",
      "Ranking documents for [207] 'bph treatment'\n",
      "Ranking documents for [208] 'doctor zhivago'\n",
      "Ranking documents for [209] 'land surveyor'\n",
      "Ranking documents for [210] 'golf gps'\n",
      "Ranking documents for [211] 'what is madagascar known for'\n",
      "Ranking documents for [212] 'home theater systems'\n",
      "Ranking documents for [213] 'carpal tunnel syndrome'\n",
      "Ranking documents for [214] 'capital gains tax rate'\n",
      "Ranking documents for [215] 'maryland department of natural resources'\n",
      "Ranking documents for [216] 'nicolas cage movies'\n",
      "Ranking documents for [217] 'kids earth day activities'\n",
      "Ranking documents for [218] 'solar water fountains'\n",
      "Ranking documents for [219] 'what was the name of elvis presley's home'\n",
      "Ranking documents for [220] 'nba records'\n",
      "Ranking documents for [221] 'electoral college 2008 results'\n",
      "Ranking documents for [222] 'male menopause'\n",
      "Ranking documents for [223] 'usda food pyramid'\n",
      "Ranking documents for [224] 'making chicken soup from scratch'\n",
      "Ranking documents for [225] 'black and gold'\n",
      "Ranking documents for [226] 'traverse city'\n",
      "Ranking documents for [227] 'i will survive lyrics'\n",
      "Ranking documents for [228] 'hawaiian volcano observatories'\n",
      "Ranking documents for [229] 'beef stroganoff recipe'\n",
      "Ranking documents for [230] 'world's biggest dog'\n",
      "Ranking documents for [231] 'what are the seven deadly sins'\n",
      "Ranking documents for [232] 'hurricane Irene flooding in manville nj'\n",
      "Ranking documents for [233] 'hair dye'\n",
      "Ranking documents for [234] 'dark chocolate health benefits'\n",
      "Ranking documents for [235] 'ham radio'\n",
      "Ranking documents for [236] 'symptoms of mad cow disease in humans'\n",
      "Ranking documents for [237] 'lump in throat'\n",
      "Ranking documents for [238] 'george bush sr bio'\n",
      "Ranking documents for [239] 'frank lloyd wright biography'\n",
      "Ranking documents for [240] 'presidential middle names'\n",
      "Ranking documents for [241] 'what is a wiki'\n",
      "Ranking documents for [242] 'cannellini beans'\n",
      "Ranking documents for [243] 'afghanistan flag'\n",
      "Ranking documents for [244] 'old town scottsdale'\n",
      "Ranking documents for [245] 'roosevelt island'\n",
      "Ranking documents for [246] 'civil war battles in South Carolina'\n",
      "Ranking documents for [247] 'rain man'\n",
      "Ranking documents for [248] 'eggs shelf life'\n",
      "Ranking documents for [249] 'occupational therapist'\n",
      "Ranking documents for [250] 'ford edge problems'\n"
     ]
    }
   ],
   "source": [
    "queries = load_queries(QUERIES_FILE)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as fout:\n",
    "    fout.write(\"QueryId,DocumentId\\n\")  # header\n",
    "    for qid, query in sorted(queries.items()):\n",
    "        print(\"Ranking documents for [{}] '{}'\".format(qid, query))\n",
    "        res = search(MAIN_INDEX, query, \"content\", size=100)\n",
    "        for doc in res.get('hits', {}).get(\"hits\", {}):\n",
    "            fout.write(\"{},{}\\n\".format(qid, doc.get(\"_id\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exists\n",
    "\n",
    "Checking whether the given document ID exists in that index using [es.exists()](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.Elasticsearch.exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def exists(indexname, doc_id):\n",
    "    url = \"/\".join([API, indexname, doc_id, \"_exists\"])\n",
    "    response = requests.get(url).text\n",
    "    return json.loads(response)['exists']\n",
    "    \n",
    "print(exists(MAIN_INDEX, \"clueweb12-0713wb-35-00870\"))\n",
    "print(exists(MAIN_INDEX, \"clueweb12-0906wb-09-33744\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer\n",
    "\n",
    "Returns the analyzed version of the input text using [es.indices.analyze()](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.client.IndicesClient.analyze).\n",
    "\n",
    "Instead of just splitting on spaces, use this request for tokenizing the query text.\n",
    "\n",
    "Parameters:\n",
    "  - `text` (mandatory): text to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what was the name of elvis presley's home => ['what', 'name', 'elvi', 'preslei', 'home']\n"
     ]
    }
   ],
   "source": [
    "def analyze_query(indexname, query):\n",
    "    url = \"/\".join([API, indexname, \"_analyze\"]) + \"?\" \\\n",
    "          + urllib.parse.urlencode({\"text\": query})\n",
    "    response = requests.get(url).text\n",
    "    r = json.loads(response)\n",
    "    return [t[\"token\"] for t in r[\"tokens\"]]\n",
    "    \n",
    "print(\"{} => {}\".format(queries['219'], analyze_query(MAIN_INDEX, queries['219'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Termvectors\n",
    "\n",
    "Returns information and statistics on terms in the fields of a particular document using [es.termvectors()](https://elasticsearch-py.readthedocs.io/en/master/api.html#elasticsearch.Elasticsearch.termvectors).\n",
    "\n",
    "Parameters:\n",
    "  - `term_statistics` (optional): set true to return term statistics (default is false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'field_statistics': {'doc_count': 5304355, 'sum_doc_freq': 31308821, 'sum_ttf': 34674338}, 'terms': {'bbc': {'doc_freq': 1826, 'term_freq': 1, 'ttf': 1935}, 'comput': {'doc_freq': 23036, 'term_freq': 1, 'ttf': 25856}, 'softwar': {'doc_freq': 28921, 'term_freq': 1, 'ttf': 32599}}}\n"
     ]
    }
   ],
   "source": [
    "def term_vectors(indexname, doc_id, term_statistics=False):\n",
    "    ret = {}    \n",
    "    url = \"/\".join([API, indexname, doc_id, \"_termvectors\"]) + \"?\" \\\n",
    "          + urllib.parse.urlencode({\"term_statistics\": str(term_statistics).lower()})\n",
    "    response = requests.get(url).text\n",
    "    try:\n",
    "        ret = json.loads(response)\n",
    "    except:\n",
    "        print(\"Failed to json-decode this response:\\n{}\".format(response))\n",
    "    return ret\n",
    "\n",
    "print(term_vectors(MAIN_INDEX, \"clueweb12-0713wb-35-00870\", term_statistics=True)['term_vectors']['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
