{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2B: Ranking\n",
    "\n",
    "This notebook contains the skeleton for training a model and then applying it to produce a document ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the precomputed features\n",
    "\n",
    "The code below loads the precomputed features and combines them into feature vectors for query-document pairs.\n",
    "\n",
    "For this part to work, you'll need to run the `1_Feature_computation` notebook first to generate the sample features JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_features(queries, features_to_load):\n",
    "    feature_names = []\n",
    "    features = {}\n",
    "    for f in features_to_load:\n",
    "        print(\"Loading features from {}\".format(f['file']))\n",
    "        feature_names += f['features']\n",
    "        with open(f['file']) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            \n",
    "            for q, qdocs in data.items():\n",
    "                for d, feature_values in qdocs.items():\n",
    "                    key = \"{}-{}\".format(q, d)\n",
    "                    for feature_name in f['features']:\n",
    "                        # Note: no error checking is performed. It is assumed that all feature files\n",
    "                        # contain the same queries and documents.\n",
    "                        fvect = features.get(key, [])\n",
    "                        fvect.append(feature_values[feature_name])\n",
    "                        features[key] = fvect\n",
    "\n",
    "    print(\"Feature vector: {}\".format(feature_names))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features from data/sample_features_1.json\n",
      "Loading features from data/sample_features_2.json\n",
      "Feature vector: ['qlen', 'bm25_title', 'bm25_content']\n"
     ]
    }
   ],
   "source": [
    "# Specify the features to be loaded from each file.\n",
    "# They will make up the feature vector in this exact order.\n",
    "features_to_load = [\n",
    "    {\n",
    "        'file': \"data/sample_features_1.json\",\n",
    "        'features': [\"qlen\"]\n",
    "    },  # feature 1\n",
    "    {\n",
    "        'file': \"data/sample_features_2.json\",\n",
    "        'features': [\"bm25_title\", \"bm25_content\"]\n",
    "    }  # feature 2, feature 3\n",
    "]\n",
    "\n",
    "features = load_features(queries, features_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1-d1 [1, 0, 0]\n",
      "q1-d2 [1, 0, 0]\n",
      "q1-d3 [1, 0, 0]\n",
      "q2-d1 [1, 0, 0]\n",
      "q2-d2 [1, 0, 0]\n",
      "q2-d3 [1, 0, 0]\n",
      "q3-d1 [1, 0, 0]\n",
      "q3-d2 [1, 0, 0]\n",
      "q3-d3 [1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# This is how the feature vectors look like\n",
    "for k, v in features.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "Training needs to be done differently based on the scenario:\n",
    "\n",
    "  * **Scenario 1**: The model is trained using cross-validation, that is on 4/5 of queries, then applied on the remaining 1/5 of queries (repeated 5 times).\n",
    "  * **Scenario 2**: The model is trained on all available training data.\n",
    "  \n",
    "The feature vectors at this point are already created. These should contain both (a) the training queries and (b) the queries on which you want to apply your model.\n",
    "\n",
    "Train your model on queries (a). For that you'll also need to load the corresponding relevance labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the model to produce a ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the train model on queries (b) and sort documents according to the predicted relevance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
