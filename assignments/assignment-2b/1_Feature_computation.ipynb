{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 2B: Feature computation\n",
    "\n",
    "The purpose of this notebook is to perform the computation of features. \n",
    "\n",
    "Note that some features might be expensive, so you don't want to keep re-computing them. Instead, aim for writing a set of relatively simple feature extractors, each computing one or multiple features, and save their output to separate files. Then, load the pre-computed features from multiple files in the learning step (in the [ranking notebook](2_Ranking.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example feature extractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_qlen(query, doc):\n",
    "    \"\"\"Feature: query length (number of terms). \n",
    "    This is a query feature, so it'll have the same value for all documents.\"\"\"\n",
    "    return len(query.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_bm25(query, doc, field):\n",
    "    \"\"\"Feature: BM25 retrieval score on a given field.\"\"\"\n",
    "    # TODO\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature computation\n",
    "\n",
    "Computes features for document-query pairs and saves them to a file.\n",
    "\n",
    "Specifically, we will save features to a JSON file, using a nested map structure, with queries on the first level, documents on the second level, and individual features on the third level. \n",
    "\n",
    "```python\n",
    "  features = {\n",
    "      'query_i': {\n",
    "          'doc_j': {\n",
    "              'feature_1': 0,  # value of feature_1 for (query_i, doc_j) pair\n",
    "              'feature_2': 0,  # value of feature_2 for (query_i, doc_j) pair\n",
    "              ...\n",
    "          }\n",
    "          ...\n",
    "      }\n",
    "      ...\n",
    "  }\n",
    "```\n",
    "\n",
    "**Note**: The set of documents for a query (for which you want to compute features) should be a combination of the documents for which you have relevance labels and the top-100 documents retrieved in first-pass retrieval.\n",
    "You can then decide in the learning part if/how you want to deal with class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO load actual queries from file\n",
    "queries = [\"q1\", \"q2\", \"q3\"]\n",
    "\n",
    "features_1 = {}\n",
    "features_2 = {}\n",
    "\n",
    "for q in queries:\n",
    "    features_1[q] = {}\n",
    "    features_2[q] = {}\n",
    "    # TODO load actual candidate documents from file\n",
    "    docs = [\"d1\", \"d2\", \"d3\"]\n",
    "    for d in docs:\n",
    "        # Here, two sets of features are computed in a single go to produce some toy data.\n",
    "        # Normally, you would run these sequentially.\n",
    "        features_1[q][d] = {\n",
    "            'qlen': feature_qlen(q, d)\n",
    "        }\n",
    "        features_2[q][d] = {\n",
    "            'bm25_content': feature_bm25(q, d, \"content\"),\n",
    "            'bm25_title': feature_bm25(q, d, \"title\")\n",
    "        }\n",
    "        \n",
    "# Write computed features to file\n",
    "with open(\"data/sample_features_1.json\", \"w\") as f:\n",
    "    json.dump(features_1, f, indent=4, sort_keys=True)\n",
    "    \n",
    "with open(\"data/sample_features_2.json\", \"w\") as f:\n",
    "    json.dump(features_2, f, indent=4, sort_keys=True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
